{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Author : Amir Shokri\n",
    "##### github link : https://github.com/amirshnll/Abalone\n",
    "##### dataset link : http://archive.ics.uci.edu/ml/datasets/Abalone\n",
    "##### email : amirsh.nll@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file\n",
    "df = pd.read_csv(\"D:\\\\abalone.txt\", header=None)\n",
    "for char in df:\n",
    "    df = df.replace('M','1')\n",
    "    df = df.replace('F','-1')\n",
    "    df = df.replace('I','0')\n",
    "df\n",
    "\n",
    "#separate the feature columns from the target column.\n",
    "features = [0,1,2,3,4,5,6,7]\n",
    "X = df[features]\n",
    "y = df[8]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the Training data and Test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size=0.2)\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally for the MLP- Multilayer Perceptron\n",
    "mlp = MLPClassifier(max_iter=1000)  \n",
    "mlp.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the prediction step, the model is used to predict the response for given data.\n",
    "predictions = mlp.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  8  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3 10  5  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  5 14 22  9  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  8 36 26  8  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3 22 34 38  8  0  0  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  9 32 54 30  5  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  8 12 60 28 28  1  6  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  4 31 21 25  4  6  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  1 23 16 14  0  6  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  3  4  9 15  1  6  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2 10  2  1  6  1  0  1  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  3  8  5  1  3  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  4  1  0  2  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  3  3  2  1  1  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  3  4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  3  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.53      0.73      0.62        11\n",
      "           5       0.56      0.50      0.53        20\n",
      "           6       0.45      0.26      0.33        53\n",
      "           7       0.35      0.45      0.39        80\n",
      "           8       0.28      0.32      0.30       107\n",
      "           9       0.23      0.41      0.30       132\n",
      "          10       0.20      0.20      0.20       143\n",
      "          11       0.24      0.27      0.26        91\n",
      "          12       0.00      0.00      0.00        63\n",
      "          13       0.13      0.15      0.14        39\n",
      "          14       0.50      0.04      0.08        24\n",
      "          15       0.00      0.00      0.00        21\n",
      "          16       0.15      0.20      0.17        10\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        10\n",
      "          19       0.00      0.00      0.00         7\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.26       836\n",
      "   macro avg       0.16      0.16      0.15       836\n",
      "weighted avg       0.24      0.26      0.24       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Last thing: evaluation of algorithm performance in classifying \n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
